{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fe1713",
   "metadata": {},
   "source": [
    "# Notebook 0. About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72910c42",
   "metadata": {},
   "source": [
    "## 1. Description\n",
    "\n",
    "The Twitter Sentiment Analysis dataset combines annotations from two sentiment analysis approaches: Roberta (a transformer-based NLP model) and Vader (a lexicon-based sentiment analyzer).\n",
    "\n",
    "Each entry in the dataset represents a tweet, along with its sentiment label, which is typically classified as positive, neutral, or negative. Additional metadata, such as tweet ID, user, and date, may also be included depending on the CSV version.\n",
    "\n",
    "This dataset is useful for training, evaluating, and demonstrating sentiment analysis models. It is small enough to be easily handled for experiments and demonstrations while containing enough diversity to show real-world variations in tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a80c57",
   "metadata": {},
   "source": [
    "## 2. Load the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281a7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = '../data/tweets.csv'\n",
    "df = pd.read_csv(file_path).sort_values(by='Created At')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad86245",
   "metadata": {},
   "source": [
    "## 3. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main set shape: (800, 7)\n",
      "Update1 set shape: (100, 7)\n",
      "Update2 set shape: (100, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split into main (80%) and updates (20%) sets\n",
    "main_df, updates_df = train_test_split(df, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "\n",
    "# Split into main (80%) and updates (20%) sets\n",
    "update1_df, update2_df = train_test_split(updates_df, test_size=0.5, shuffle=False, random_state=42)\n",
    "\n",
    "\n",
    "print(\"\\nMain set shape:\", main_df.shape)\n",
    "print(\"Update1 set shape:\", update1_df.shape)\n",
    "print(\"Update2 set shape:\", update2_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96651b",
   "metadata": {},
   "source": [
    "## 4. Save splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd56c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main/updates CSV files saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main_df.to_csv('../data/main.csv', index=False)\n",
    "update1_df.to_csv('../data/update1.csv', index=False)\n",
    "update2_df.to_csv('../data/update2.csv', index=False)\n",
    "\n",
    "print(\"Main/updates CSV files saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-management-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
